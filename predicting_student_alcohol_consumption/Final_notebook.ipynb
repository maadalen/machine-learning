{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dummy_variable(columns, dataframe):\n",
    "    enc = OneHotEncoder()\n",
    "    labler = LabelEncoder()\n",
    "    \n",
    "    for colname in columns:\n",
    "        labels = labler.fit_transform(dataframe[colname])\n",
    "        labels = labels.reshape(-1,1)\n",
    "        categor_vars = enc.fit_transform(labels)\n",
    "        categor_vars = categor_vars.toarray()\n",
    "        df = pd.DataFrame(categor_vars)\n",
    "        columns = df.columns\n",
    "        column_labels = labler.inverse_transform(columns)\n",
    "        df.columns = [str(col) + \"_\" + colname for col in column_labels]\n",
    "\n",
    "        del dataframe[colname]\n",
    "        dataframe = pd.concat([dataframe.reset_index(drop=True), df.iloc[:,:-1].reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    return dataframe \n",
    "\n",
    "def cross_val(estimator, x, y, k=10, reg=True):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import numpy as np\n",
    "    \n",
    "    \n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    score = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, Y_train = x.iloc[train_index,:], y[train_index] \n",
    "        X_test, Y_test = x.iloc[test_index,:], y[test_index]\n",
    "        \n",
    "        estimator.fit(X_train, Y_train)\n",
    "        y_predict = estimator.predict(X_test)\n",
    "        if reg:\n",
    "            score.append(mean_squared_error(Y_test, y_predict))\n",
    "        else:\n",
    "            score.append(accuracy_score(Y_test, y_predict))\n",
    "    return np.mean(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "port = pd.read_csv('student-por.csv', sep=\";\")\n",
    "# port['class'] = \"portuguese\"\n",
    "math = pd.read_csv('student-mat.csv', sep=\";\")\n",
    "# math['class'] = 'math'\n",
    "data = math.merge(port, left_on = [\"school\",\"sex\",\"age\",\"address\",\"famsize\",\"Pstatus\",\"Medu\",\"Fedu\",\"Mjob\",\"Fjob\",\"reason\",\"nursery\",\"internet\"],\n",
    "                 right_on = [\"school\",\"sex\",\"age\",\"address\",\"famsize\",\"Pstatus\",\"Medu\",\"Fedu\",\"Mjob\",\"Fjob\",\"reason\",\"nursery\",\"internet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(port.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'school', u'sex', u'age', u'address', u'famsize', u'Pstatus', u'Medu',\n",
       "       u'Fedu', u'Mjob', u'Fjob', u'reason', u'guardian_x', u'traveltime_x',\n",
       "       u'studytime_x', u'failures_x', u'schoolsup_x', u'famsup_x', u'paid_x',\n",
       "       u'activities_x', u'nursery', u'higher_x', u'internet', u'romantic_x',\n",
       "       u'famrel_x', u'freetime_x', u'goout_x', u'Dalc_x', u'Walc_x',\n",
       "       u'health_x', u'absences_x', u'G1_x', u'G2_x', u'G3_x', u'guardian_y',\n",
       "       u'traveltime_y', u'studytime_y', u'failures_y', u'schoolsup_y',\n",
       "       u'famsup_y', u'paid_y', u'activities_y', u'higher_y', u'romantic_y',\n",
       "       u'famrel_y', u'freetime_y', u'goout_y', u'Dalc_y', u'Walc_y',\n",
       "       u'health_y', u'absences_y', u'G1_y', u'G2_y', u'G3_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.drop(['guardian_x', 'traveltime_x',\n",
    "       'studytime_x', 'failures_x', 'schoolsup_x', 'famsup_x', 'paid_x',\n",
    "       'activities_x', 'higher_x', 'romantic_x',\n",
    "       'famrel_x', 'freetime_x', 'goout_x', 'Dalc_x', 'Walc_x',\n",
    "       'health_x', 'absences_x'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'school', u'sex', u'age', u'address', u'famsize', u'Pstatus', u'Medu',\n",
       "       u'Fedu', u'Mjob', u'Fjob', u'reason', u'nursery', u'internet', u'G1_x',\n",
       "       u'G2_x', u'G3_x', u'guardian_y', u'traveltime_y', u'studytime_y',\n",
       "       u'failures_y', u'schoolsup_y', u'famsup_y', u'paid_y', u'activities_y',\n",
       "       u'higher_y', u'romantic_y', u'famrel_y', u'freetime_y', u'goout_y',\n",
       "       u'Dalc_y', u'Walc_y', u'health_y', u'absences_y', u'G1_y', u'G2_y',\n",
       "       u'G3_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = data.drop_duplicates([\"school\",\"sex\",\"age\",\"address\",\"famsize\",\"Pstatus\",\"Medu\",\"Fedu\",\"Mjob\",\"Fjob\",\"reason\",\"nursery\",\"internet\"])\n",
    "# data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = data['Walc_y']\n",
    "#Y = (data['Walc'] * 2 + data['Dalc'] * 5) / 7.0\n",
    "#Y = Y >= 3\n",
    "X = data.drop(['Walc_y'], axis=1)\n",
    "columns = [u'school', u'sex', u'address', u'famsize', u'Pstatus', u'Medu',\n",
    "       u'Fedu', u'Mjob', u'Fjob', u'reason', u'nursery', u'internet', u'guardian_y', u'traveltime_y', u'studytime_y',\n",
    "           u'schoolsup_y', u'famsup_y', u'paid_y', u'activities_y',\n",
    "       u'higher_y', u'romantic_y', u'famrel_y', u'freetime_y', u'goout_y',\n",
    "       u'Dalc_y', u'health_y']\n",
    "X = data.loc[:,columns]\n",
    "X = dummy_variable(columns, X)\n",
    "extra_col = ['failures_y', u'G1_x',\n",
    "       u'G2_x', u'G3_x', u'G1_y', u'G2_y',\n",
    "       u'G3_y','absences_y', 'age']\n",
    "X = pd.concat([X, data.loc[:,extra_col]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP_school</th>\n",
       "      <th>F_sex</th>\n",
       "      <th>R_address</th>\n",
       "      <th>GT3_famsize</th>\n",
       "      <th>A_Pstatus</th>\n",
       "      <th>0_Medu</th>\n",
       "      <th>1_Medu</th>\n",
       "      <th>2_Medu</th>\n",
       "      <th>3_Medu</th>\n",
       "      <th>0_Fedu</th>\n",
       "      <th>...</th>\n",
       "      <th>4_health_y</th>\n",
       "      <th>failures_y</th>\n",
       "      <th>G1_x</th>\n",
       "      <th>G2_x</th>\n",
       "      <th>G3_x</th>\n",
       "      <th>G1_y</th>\n",
       "      <th>G2_y</th>\n",
       "      <th>G3_y</th>\n",
       "      <th>absences_y</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GP_school  F_sex  R_address  GT3_famsize  A_Pstatus  0_Medu  1_Medu  \\\n",
       "0        1.0    1.0        0.0          1.0        1.0     0.0     0.0   \n",
       "1        1.0    1.0        0.0          1.0        0.0     0.0     1.0   \n",
       "2        1.0    1.0        0.0          0.0        0.0     0.0     1.0   \n",
       "3        1.0    1.0        0.0          1.0        0.0     0.0     0.0   \n",
       "4        1.0    1.0        0.0          1.0        0.0     0.0     0.0   \n",
       "\n",
       "   2_Medu  3_Medu  0_Fedu ...   4_health_y  failures_y  G1_x  G2_x  G3_x  \\\n",
       "0     0.0     0.0     0.0 ...          0.0           0     5     6     6   \n",
       "1     0.0     0.0     0.0 ...          0.0           0     5     5     6   \n",
       "2     0.0     0.0     0.0 ...          0.0           0     7     8    10   \n",
       "3     0.0     0.0     0.0 ...          0.0           0    15    14    15   \n",
       "4     0.0     1.0     0.0 ...          0.0           0     6    10    10   \n",
       "\n",
       "   G1_y  G2_y  G3_y  absences_y  age  \n",
       "0     0    11    11           4   18  \n",
       "1     9    11    11           2   17  \n",
       "2    12    13    12           6   15  \n",
       "3    14    14    14           0   15  \n",
       "4    11    13    13           0   16  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Walc_y\n",
       "1    144\n",
       "2     86\n",
       "3     76\n",
       "4     49\n",
       "5     27\n",
       "Name: Walc_y, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.groupby(Y).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4426450742240215"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val(estimator=LinearDiscriminantAnalysis(), x=X, y=Y, reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38751686909581651"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val(estimator=DecisionTreeClassifier(criterion='gini', max_depth=15), x=X, y=Y, reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48657219973009447"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "estimators=50\n",
    "cross_val(estimator=RandomForestClassifier(n_estimators = estimators, random_state=False ,class_weight='auto'), x=X, y=Y, reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41909581646423744"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "cross_val(estimator=GradientBoostingClassifier(max_depth = 50), x=X, y=Y, reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38785425101214577"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "cross_val(estimator=SVC(), x=X, y=Y, reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40829959514170044"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate = .5\n",
    "ada = AdaBoostClassifier(learning_rate=rate, random_state=False)\n",
    "cross_val(estimator=ada, x=X, y=Y, reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43927125506072873"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log = LogisticRegression()\n",
    "cross_val(estimator=log,x=X, y=Y, reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# calling fit and transform in sequence (using method chaining) \n",
    "# same result, but more efficient compbutation\n",
    "X_scaled_d = pd.DataFrame(scaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38529014844804321"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(200,200))\n",
    "\n",
    "\n",
    "cross_val(estimator=mlp,x=X_scaled_d, y=Y, reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_x, test_x, train_y, test_y = train_test_split(X,Y, train_size=.1)\n",
    "# log.fit(train_x, train_y)\n",
    "# pred_y = log.predict(test_x)\n",
    "# c = confusion_matrix(test_y, pred_y)\n",
    "# print c[1,1] / float(c[1,1] + c[1,0])\n",
    "# c"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
